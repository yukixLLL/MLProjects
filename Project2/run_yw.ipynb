{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = \"./datas/data_train.csv\"\n",
    "test_dataset = \"./datas/sampleSubmission.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path):\n",
    "    \"\"\"Load dataset as a (User, Movie, Rating) pandas dataframe\"\"\"\n",
    "    df = pd.read_csv(path)\n",
    "    parsed_df = pd.DataFrame()\n",
    "    # Get all pairs of (r44_c1) -> (44, 1) (user, movie)\n",
    "    user_movie_indices = df.Id.apply(lambda x: x.split('_'))\n",
    "    parsed_df['User'] =  [int(i[0][1:]) for i in user_movie_indices]\n",
    "    parsed_df['Movie'] = [int(i[1][1:]) for i in user_movie_indices]\n",
    "    parsed_df['Rating'] = df['Prediction']\n",
    "    num_items = parsed_df.Movie.nunique()\n",
    "    num_users = parsed_df.User.nunique()\n",
    "\n",
    "    print(\"USERS: {} ITEMS: {}\".format(num_users, num_items))\n",
    "    return parsed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USERS: 10000 ITEMS: 1000\n",
      "USERS: 10000 ITEMS: 1000\n"
     ]
    }
   ],
   "source": [
    "train_df = load_dataset(train_dataset)\n",
    "test_df = load_dataset(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(df, p_test=0.2, min_num_ratings = 0):\n",
    "    \"\"\" split dataframe into train and test set \"\"\"\n",
    "    # select user and item based on the condition.\n",
    "    user_counts = df.User.value_counts()\n",
    "    valid_users = user_counts[user_counts > min_num_ratings].index.values\n",
    "    movie_counts = df.Movie.value_counts()\n",
    "    valid_movies = movie_counts[movie_counts > min_num_ratings].index.values\n",
    "\n",
    "    valid_ratings = df[df.User.isin(valid_users) & df.Movie.isin(valid_movies)].reset_index(drop=True)\n",
    "\n",
    "    # Split data\n",
    "    size = df.shape[0]\n",
    "    indexes = list(range(size))\n",
    "    np.random.shuffle(indexes)\n",
    "    \n",
    "    test_ind = indexes[:int(size*p_test)]\n",
    "    train_ind = indexes[int(size*p_test):]\n",
    "    \n",
    "    test = valid_ratings.loc[test_ind]\n",
    "    train = valid_ratings.loc[train_ind]\n",
    "\n",
    "    print(\"Train: {}, Test: {}\".format(test.shape, train.shape))\n",
    "    \n",
    "    # Test that the sum of nb rows of splitted dataframes = nb rows of original\n",
    "    if (train.shape[0] + test.shape[0] == df.shape[0]):\n",
    "        return train.reset_index(drop=True), test.reset_index(drop=True)\n",
    "    else:\n",
    "        raise Exception(\"[Error] Train: {} + Test {} != Original: {} !!\".format(train_tr.shape[0], test_tr.shape[0], df.shape[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (235390, 3), Test: (941562, 3)\n"
     ]
    }
   ],
   "source": [
    "train_tr, test_tr = split_dataset(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rmse(pred, truth):\n",
    "    \"\"\" compute RMSE for pandas dataframes \"\"\"\n",
    "    truth_sorted = truth.sort_values(['User', 'Movie']).reset_index(drop=True)\n",
    "    pred_sorted = pred.sort_values(['User', 'Movie']).reset_index(drop=True)\n",
    "\n",
    "    truth_sorted['square_error'] = np.square(truth_sorted['Rating'] - prediction_sorted['Rating'])\n",
    "\n",
    "    mse = truth_sorted['square_error'].mean()\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preprocessing' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-2d565fdd18ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtrain_tr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstandardize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_tr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mtest_tr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstandardize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_tr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-2d565fdd18ff>\u001b[0m in \u001b[0;36mstandardize\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# Normalize in [0, 1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Rating'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mmin_max_scaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMinMaxScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mx_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin_max_scaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mdf_normalized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_scaled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'preprocessing' is not defined"
     ]
    }
   ],
   "source": [
    "def standardize(df):\n",
    "    # Normalize in [0, 1]\n",
    "    r = df['Rating'].values.astype(float)\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    x_scaled = min_max_scaler.fit_transform(r.reshape(-1,1))\n",
    "    df_normalized = pd.DataFrame(x_scaled)\n",
    "    df['Rating'] = df_normalized\n",
    "    return df\n",
    "\n",
    "train_tr = standardize(train_tr)\n",
    "test_tr = standardize(test_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 1000\n"
     ]
    }
   ],
   "source": [
    "def df_to_matrix(df):\n",
    "    # Convert DataFrame in user-item matrix\n",
    "    matrix = df.pivot(index='User', columns='Movie', values='Rating')\n",
    "    matrix.fillna(0, inplace=True)\n",
    "    # Convert to numpy matrix\n",
    "    users = matrix.index.tolist()\n",
    "    items = matrix.columns.tolist()\n",
    "\n",
    "    matrix = matrix.as_matrix()\n",
    "    return users, items, matrix\n",
    "\n",
    "users, items, matrix_tr = df_to_matrix(train_tr)\n",
    "num_users = len(users)\n",
    "num_items = len(items)\n",
    "\n",
    "print(num_users, num_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DIDN'T WORK!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from : https://vitobellini.github.io/posts/2018/01/03/how-to-build-a-recommender-system-in-tensorflow.html\n",
    "\n",
    "# Network Parameters\n",
    "\n",
    "num_input = num_items\n",
    "num_hidden_1 = 10\n",
    "num_hidden_2 = 5\n",
    "\n",
    "X = tf.placeholder(tf.float64, [None, num_input])\n",
    "\n",
    "weights = {\n",
    "    'encoder_h1': tf.Variable(tf.random_normal([num_input, num_hidden_1], dtype=tf.float64)),\n",
    "    'encoder_h2': tf.Variable(tf.random_normal([num_hidden_1, num_hidden_2], dtype=tf.float64)),\n",
    "    'decoder_h1': tf.Variable(tf.random_normal([num_hidden_2, num_hidden_1], dtype=tf.float64)),\n",
    "    'decoder_h2': tf.Variable(tf.random_normal([num_hidden_1, num_input], dtype=tf.float64)),\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'encoder_b1': tf.Variable(tf.random_normal([num_hidden_1], dtype=tf.float64)),\n",
    "    'encoder_b2': tf.Variable(tf.random_normal([num_hidden_2], dtype=tf.float64)),\n",
    "    'decoder_b1': tf.Variable(tf.random_normal([num_hidden_1], dtype=tf.float64)),\n",
    "    'decoder_b2': tf.Variable(tf.random_normal([num_input], dtype=tf.float64)),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the encoder\n",
    "\n",
    "def encoder(x):\n",
    "    # Encoder Hidden layer with sigmoid activation #1\n",
    "    layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(x, weights['encoder_h1']), biases['encoder_b1']))\n",
    "    # Encoder Hidden layer with sigmoid activation #2\n",
    "    layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, weights['encoder_h2']), biases['encoder_b2']))\n",
    "    return layer_2\n",
    "\n",
    "\n",
    "# Building the decoder\n",
    "\n",
    "def decoder(x):\n",
    "    # Decoder Hidden layer with sigmoid activation #1\n",
    "    layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(x, weights['decoder_h1']), biases['decoder_b1']))\n",
    "    # Decoder Hidden layer with sigmoid activation #2\n",
    "    layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, weights['decoder_h2']), biases['decoder_b2']))\n",
    "    return layer_2\n",
    "\n",
    "\n",
    "# Construct model\n",
    "\n",
    "encoder_op = encoder(X)\n",
    "decoder_op = decoder(encoder_op)\n",
    "\n",
    "\n",
    "# Prediction\n",
    "\n",
    "y_pred = decoder_op\n",
    "\n",
    "\n",
    "# Targets are the input data.\n",
    "\n",
    "y_true = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss and optimizer, minimize the squared error\n",
    "\n",
    "loss = tf.losses.mean_squared_error(y_true, y_pred)\n",
    "optimizer = tf.train.RMSPropOptimizer(0.03).minimize(loss)\n",
    "\n",
    "predictions = pd.DataFrame()\n",
    "\n",
    "# Define evaluation metrics\n",
    "\n",
    "eval_x = tf.placeholder(tf.int32, )\n",
    "eval_y = tf.placeholder(tf.int32, )\n",
    "pre, pre_op = tf.metrics.precision(labels=eval_x, predictions=eval_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the variables (i.e. assign their default value)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "local_init = tf.local_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0. , 0. , 0. , ..., 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , ..., 1. , 0. , 0.5],\n",
       "       [0. , 0. , 0. , ..., 0. , 0. , 0. ],\n",
       "       ...,\n",
       "       [0. , 0. , 0. , ..., 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , ..., 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , ..., 0. , 0. , 0.5]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = matrix_tr.copy()\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Loss: 0.33865233287215235\n",
      "Epoch: 2 Loss: 0.33617846965789794\n",
      "Epoch: 3 Loss: 0.31951463147997855\n",
      "Epoch: 4 Loss: 0.2501043420284986\n",
      "Epoch: 5 Loss: 0.1083067674189806\n",
      "Epoch: 6 Loss: 0.051446060091257094\n",
      "Epoch: 7 Loss: 0.04880251819267869\n",
      "Epoch: 8 Loss: 0.04830874148756266\n",
      "Epoch: 9 Loss: 0.04717384213581681\n",
      "Epoch: 10 Loss: 0.04601081358268857\n",
      "Epoch: 11 Loss: 0.045704937912523745\n",
      "Epoch: 12 Loss: 0.0455327108502388\n",
      "Epoch: 13 Loss: 0.045409477315843105\n",
      "Epoch: 14 Loss: 0.045302273239940405\n",
      "Epoch: 15 Loss: 0.04522054763510823\n",
      "Epoch: 16 Loss: 0.045146352518349885\n",
      "Epoch: 17 Loss: 0.04511649133637548\n",
      "Epoch: 18 Loss: 0.0450407731346786\n",
      "Epoch: 19 Loss: 0.04499190943315625\n",
      "Epoch: 20 Loss: 0.044984130375087264\n",
      "Epoch: 21 Loss: 0.04493501167744398\n",
      "Epoch: 22 Loss: 0.04489314304664731\n",
      "Epoch: 23 Loss: 0.044886811077594756\n",
      "Epoch: 24 Loss: 0.04482487924396992\n",
      "Epoch: 25 Loss: 0.04484245739877224\n",
      "Epoch: 26 Loss: 0.04480467587709427\n",
      "Epoch: 27 Loss: 0.044766230136156084\n",
      "Epoch: 28 Loss: 0.044736027158796786\n",
      "Epoch: 29 Loss: 0.04477565037086606\n",
      "Epoch: 30 Loss: 0.04470333745703101\n",
      "Epoch: 31 Loss: 0.04472107756882906\n",
      "Epoch: 32 Loss: 0.04468234172090888\n",
      "Epoch: 33 Loss: 0.04466209216043353\n",
      "Epoch: 34 Loss: 0.04466738793998957\n",
      "Epoch: 35 Loss: 0.044618974532932044\n",
      "Epoch: 36 Loss: 0.04464649436995387\n",
      "Epoch: 37 Loss: 0.04460823470726609\n",
      "Epoch: 38 Loss: 0.04458524528890848\n",
      "Epoch: 39 Loss: 0.04458816070109606\n",
      "Epoch: 40 Loss: 0.04457164946943522\n",
      "Epoch: 41 Loss: 0.04455391857773065\n",
      "Epoch: 42 Loss: 0.0445655208081007\n",
      "Epoch: 43 Loss: 0.044530633557587865\n",
      "Epoch: 44 Loss: 0.04452999262139201\n",
      "Epoch: 45 Loss: 0.044500865135341884\n",
      "Epoch: 46 Loss: 0.04450207781046629\n",
      "Epoch: 47 Loss: 0.04448799081146717\n",
      "Epoch: 48 Loss: 0.0444696668535471\n",
      "Epoch: 49 Loss: 0.04448767984285951\n",
      "Epoch: 50 Loss: 0.044455155916512015\n",
      "Epoch: 51 Loss: 0.04445903664454818\n",
      "Epoch: 52 Loss: 0.04443043079227209\n",
      "Epoch: 53 Loss: 0.0444074934348464\n",
      "Epoch: 54 Loss: 0.044445902667939664\n",
      "Epoch: 55 Loss: 0.04441371327266097\n",
      "Epoch: 56 Loss: 0.044391130283474925\n",
      "Epoch: 57 Loss: 0.044410888012498616\n",
      "Epoch: 58 Loss: 0.04437300069257617\n",
      "Epoch: 59 Loss: 0.0443827249109745\n",
      "Epoch: 60 Loss: 0.044358399044722316\n",
      "Epoch: 61 Loss: 0.04433533139526844\n",
      "Epoch: 62 Loss: 0.04435667209327221\n",
      "Epoch: 63 Loss: 0.044338295422494414\n",
      "Epoch: 64 Loss: 0.0443241068162024\n",
      "Epoch: 65 Loss: 0.044301016815006734\n",
      "Epoch: 66 Loss: 0.04431061614304781\n",
      "Epoch: 67 Loss: 0.04429475627839565\n",
      "Epoch: 68 Loss: 0.04426982682198286\n",
      "Epoch: 69 Loss: 0.0442534577101469\n",
      "Epoch: 70 Loss: 0.044303194340318444\n",
      "Epoch: 71 Loss: 0.044235889427363874\n",
      "Epoch: 72 Loss: 0.044267417211085555\n",
      "Epoch: 73 Loss: 0.04423698522150517\n",
      "Epoch: 74 Loss: 0.04421449145302177\n",
      "Epoch: 75 Loss: 0.04423879766836762\n",
      "Epoch: 76 Loss: 0.04420651812106371\n",
      "Epoch: 77 Loss: 0.04420016659423709\n",
      "Epoch: 78 Loss: 0.044193525519222024\n",
      "Epoch: 79 Loss: 0.04418654423207045\n",
      "Epoch: 80 Loss: 0.04418487306684256\n",
      "Epoch: 81 Loss: 0.044166828598827125\n",
      "Epoch: 82 Loss: 0.044170218612998725\n",
      "Epoch: 83 Loss: 0.04414757704362273\n",
      "Epoch: 84 Loss: 0.044145706482231616\n",
      "Epoch: 85 Loss: 0.04413016336038709\n",
      "Epoch: 86 Loss: 0.04411067208275199\n",
      "Epoch: 87 Loss: 0.044128856901079413\n",
      "Epoch: 88 Loss: 0.044125120900571344\n",
      "Epoch: 89 Loss: 0.044094237685203555\n",
      "Epoch: 90 Loss: 0.044107076991349456\n",
      "Epoch: 91 Loss: 0.04408998629078269\n",
      "Epoch: 92 Loss: 0.044079163763672116\n",
      "Epoch: 93 Loss: 0.04409637292847037\n",
      "Epoch: 94 Loss: 0.04408256001770496\n",
      "Epoch: 95 Loss: 0.04406386138871312\n",
      "Epoch: 96 Loss: 0.04406011076644063\n",
      "Epoch: 97 Loss: 0.04404389569535851\n",
      "Epoch: 98 Loss: 0.04405580749735236\n",
      "Epoch: 99 Loss: 0.044033596850931646\n",
      "Epoch: 100 Loss: 0.04402221208438277\n",
      "Predictions...\n",
      "Filtering out items in training set\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    epochs = 100\n",
    "    batch_size = 250\n",
    "\n",
    "    session.run(init)\n",
    "    session.run(local_init)\n",
    "    \n",
    "    num_batches = int(matrix.shape[0] / batch_size)\n",
    "    matrix = np.array_split(matrix, num_batches)\n",
    "\n",
    "    for i in range(epochs):\n",
    "\n",
    "        avg_cost = 0\n",
    "\n",
    "        for batch in matrix:\n",
    "            _, l = session.run([optimizer, loss], feed_dict={X: batch})\n",
    "            avg_cost += l\n",
    "\n",
    "        avg_cost /= num_batches\n",
    "\n",
    "        print(\"Epoch: {} Loss: {}\".format(i + 1, avg_cost))\n",
    "\n",
    "    print(\"Predictions...\")\n",
    "\n",
    "    matrix = np.concatenate(matrix, axis=0)\n",
    "\n",
    "    preds = session.run(decoder_op, feed_dict={X: matrix})\n",
    "\n",
    "    predictions = predictions.append(pd.DataFrame(preds))\n",
    "\n",
    "    predictions = predictions.stack().reset_index(name='Rating')\n",
    "    predictions.columns = ['User', 'Movie', 'Rating']\n",
    "    predictions['User'] = predictions['User'].map(lambda value: users[value])\n",
    "    predictions['Movie'] = predictions['Movie'].map(lambda value: items[value])\n",
    "    \n",
    "    print(\"Filtering out items in training set\")\n",
    "\n",
    "    keys = ['User', 'Movie']\n",
    "    i1 = predictions.set_index(keys).index\n",
    "    df = train_tr.copy()\n",
    "    i2 = df.set_index(keys).index\n",
    "\n",
    "    #recs = predictions[~i1.isin(i2)]\n",
    "    recs = predictions[i1.isin(i2)]\n",
    "    recs = recs.sort_values(['User', 'Rating'], ascending=[True, False])\n",
    "    recs = recs.groupby('User').head(10)\n",
    "   # recs.to_csv('recs.tsv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = recs.sort_values(by=['User', 'Movie']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = train_tr.sort_values(by=['User', 'Movie']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = predictions.set_index(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = t.merge(r, how='inner', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Surprise\n",
    "\n",
    "from: https://github.com/NicolasHug/Surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import *\n",
    "from surprise.model_selection import KFold\n",
    "from surprise import accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(train, test, **kwargs):\n",
    "    \"\"\"\n",
    "    K Nearest Neighbors with Baseline from library Surprise\n",
    "    Args:\n",
    "        train (pandas.DataFrame): train set\n",
    "        test (pandas.DataFrame): test set\n",
    "        **kwargs: Arbitrary keyword arguments.\n",
    "            k (int): Number of nearest neighbor for the algorithm\n",
    "            sim_options (dict): Dictionary specific for the kNN algorithms in Surprise\n",
    "    Returns:\n",
    "        pandas.DataFrame: predictions, sorted by (Movie, User)\n",
    "    \"\"\"\n",
    "\n",
    "    # Get parameters\n",
    "    k = kwargs['k']\n",
    "    sim_options = kwargs['sim_options']\n",
    "\n",
    "    # First, we need to dump the pandas DF into files\n",
    "    train_file = 'tmp_train.csv'\n",
    "    test_file = 'tmp_test.csv'\n",
    "    train.to_csv(train_file, index=False, header=False)\n",
    "    test.to_csv(test_file, index=False, header=False)\n",
    "\n",
    "    # Create Reader\n",
    "    reader = Reader(line_format='user item rating', sep=',')\n",
    "\n",
    "    # Train and test set for Surprise\n",
    "    fold = [(train_file, test_file)]\n",
    "\n",
    "    # Load the data\n",
    "    data = Dataset.load_from_folds(fold, reader=reader)\n",
    "\n",
    "    # Algorithm\n",
    "    algo = KNNBaseline(k=k, sim_options=sim_options)\n",
    "\n",
    "    # Go through 1 fold\n",
    "    for trainset, testset in data.folds():\n",
    "        # Train\n",
    "        algo.train(trainset)\n",
    "\n",
    "        # Predict\n",
    "        predictions = algo.test(testset)\n",
    "\n",
    "    # Postprocess the predictions\n",
    "    pred = np.zeros(len(predictions))\n",
    "    for i in range(len(predictions)):\n",
    "        val = predictions[i].est\n",
    "        if val > 5:\n",
    "            pred[i] = 5\n",
    "        elif val < 1:\n",
    "            pred[i] = 1\n",
    "        else:\n",
    "            pred[i] = val\n",
    "\n",
    "    # Copy the test\n",
    "    df_return = test.copy()\n",
    "    df_return.Rating = pred\n",
    "\n",
    "    return df_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.0266\n",
      "RMSE: 1.0249\n",
      "RMSE: 1.0281\n",
      "RMSE: 1.0273\n",
      "RMSE: 1.0288\n"
     ]
    }
   ],
   "source": [
    "\n",
    "k_fold = 5\n",
    "verbose = True\n",
    "\n",
    "train_full = train_tr.append(test_tr)\n",
    "\n",
    "# reader with rating scale\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "# load data from df\n",
    "data = Dataset.load_from_df(train_full, reader)\n",
    "\n",
    "kf = KFold(n_splits=k_fold)\n",
    "\n",
    "algo = SVD()\n",
    "\n",
    "rmses = dict()\n",
    "\n",
    "for trainset, testset in kf.split(data):\n",
    "\n",
    "    # train and test algorithm.\n",
    "    model = algo.fit(trainset)\n",
    "    predictions = algo.test(testset)\n",
    "\n",
    "    # Compute and print RMSE\n",
    "    rmse_ = accuracy.rmse(predictions, verbose=verbose)\n",
    "\n",
    "    rmses[rmse_] = model\n",
    "\n",
    "# Find the model with least RMSE\n",
    "lowest_rmse = min(rmses.keys())\n",
    "best_model = rmses[lowest_rmse]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the model with least RMSE\n",
    "lowest_rmse = min(rmses.keys())\n",
    "best_model = rmses[lowest_rmse]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User</th>\n",
       "      <th>Movie</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>86</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User  Movie  Rating\n",
       "0    44      1       4\n",
       "1    61      1       3\n",
       "2    67      1       4\n",
       "3    72      1       3\n",
       "4    86      1       5"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.220898973079219"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.predict(72, 1, None).est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test_df.copy()\n",
    "for index, row in test.iterrows():\n",
    "    user = row.User\n",
    "    movie = row.Movie\n",
    "    row.Rating = best_model.predict(user, movie).est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submission_table(original_df, col_userID, col_movie, col_rate):\n",
    "    \"\"\" return table according with Kaggle convention \"\"\"\n",
    "\n",
    "    def id(row):\n",
    "        return 'r' + str(round(row[col_userID])) + '_c' + str(round(row[col_movie]))\n",
    "\n",
    "    def pred(row):\n",
    "        return row[col_rate]\n",
    "\n",
    "    df = pd.DataFrame.copy(original_df)\n",
    "    df['Id'] = df.apply(id, axis=1)\n",
    "    df['Prediction'] = df.apply(pred, axis=1)\n",
    "\n",
    "    return df[['Id', 'Prediction']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = submission_table(test, 'User', 'Movie', 'Rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"suprise_svd.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>r37_c1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>r73_c1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>r156_c1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r160_c1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>r248_c1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>r256_c1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>r284_c1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>r400_c1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>r416_c1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>r456_c1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>r474_c1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>r495_c1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>r515_c1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>r518_c1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>r521_c1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>r559_c1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>r596_c1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>r614_c1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>r621_c1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>r661_c1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>r697_c1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>r710_c1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>r713_c1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>r732_c1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>r807_c1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>r824_c1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>r926_c1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>r951_c1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>r1000_c1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>r1141_c1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176922</th>\n",
       "      <td>r9786_c1000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176923</th>\n",
       "      <td>r9791_c1000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176924</th>\n",
       "      <td>r9797_c1000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176925</th>\n",
       "      <td>r9799_c1000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176926</th>\n",
       "      <td>r9801_c1000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176927</th>\n",
       "      <td>r9809_c1000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176928</th>\n",
       "      <td>r9814_c1000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176929</th>\n",
       "      <td>r9817_c1000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176930</th>\n",
       "      <td>r9823_c1000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176931</th>\n",
       "      <td>r9830_c1000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176932</th>\n",
       "      <td>r9831_c1000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176933</th>\n",
       "      <td>r9836_c1000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176934</th>\n",
       "      <td>r9851_c1000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176935</th>\n",
       "      <td>r9862_c1000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176936</th>\n",
       "      <td>r9880_c1000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176937</th>\n",
       "      <td>r9885_c1000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176938</th>\n",
       "      <td>r9889_c1000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176939</th>\n",
       "      <td>r9896_c1000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176940</th>\n",
       "      <td>r9901_c1000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176941</th>\n",
       "      <td>r9924_c1000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176942</th>\n",
       "      <td>r9928_c1000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176943</th>\n",
       "      <td>r9930_c1000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176944</th>\n",
       "      <td>r9939_c1000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176945</th>\n",
       "      <td>r9941_c1000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176946</th>\n",
       "      <td>r9965_c1000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176947</th>\n",
       "      <td>r9974_c1000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176948</th>\n",
       "      <td>r9977_c1000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176949</th>\n",
       "      <td>r9978_c1000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176950</th>\n",
       "      <td>r9982_c1000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176951</th>\n",
       "      <td>r9996_c1000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1176952 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Id  Prediction\n",
       "0             r37_c1           3\n",
       "1             r73_c1           2\n",
       "2            r156_c1           3\n",
       "3            r160_c1           3\n",
       "4            r248_c1           3\n",
       "5            r256_c1           3\n",
       "6            r284_c1           2\n",
       "7            r400_c1           3\n",
       "8            r416_c1           3\n",
       "9            r456_c1           3\n",
       "10           r474_c1           2\n",
       "11           r495_c1           3\n",
       "12           r515_c1           1\n",
       "13           r518_c1           3\n",
       "14           r521_c1           4\n",
       "15           r559_c1           3\n",
       "16           r596_c1           3\n",
       "17           r614_c1           3\n",
       "18           r621_c1           3\n",
       "19           r661_c1           3\n",
       "20           r697_c1           2\n",
       "21           r710_c1           3\n",
       "22           r713_c1           2\n",
       "23           r732_c1           3\n",
       "24           r807_c1           2\n",
       "25           r824_c1           3\n",
       "26           r926_c1           2\n",
       "27           r951_c1           3\n",
       "28          r1000_c1           3\n",
       "29          r1141_c1           3\n",
       "...              ...         ...\n",
       "1176922  r9786_c1000           4\n",
       "1176923  r9791_c1000           4\n",
       "1176924  r9797_c1000           3\n",
       "1176925  r9799_c1000           4\n",
       "1176926  r9801_c1000           4\n",
       "1176927  r9809_c1000           3\n",
       "1176928  r9814_c1000           2\n",
       "1176929  r9817_c1000           3\n",
       "1176930  r9823_c1000           3\n",
       "1176931  r9830_c1000           3\n",
       "1176932  r9831_c1000           3\n",
       "1176933  r9836_c1000           4\n",
       "1176934  r9851_c1000           3\n",
       "1176935  r9862_c1000           3\n",
       "1176936  r9880_c1000           4\n",
       "1176937  r9885_c1000           4\n",
       "1176938  r9889_c1000           3\n",
       "1176939  r9896_c1000           3\n",
       "1176940  r9901_c1000           4\n",
       "1176941  r9924_c1000           3\n",
       "1176942  r9928_c1000           3\n",
       "1176943  r9930_c1000           3\n",
       "1176944  r9939_c1000           3\n",
       "1176945  r9941_c1000           3\n",
       "1176946  r9965_c1000           3\n",
       "1176947  r9974_c1000           3\n",
       "1176948  r9977_c1000           3\n",
       "1176949  r9978_c1000           3\n",
       "1176950  r9982_c1000           3\n",
       "1176951  r9996_c1000           3\n",
       "\n",
       "[1176952 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
